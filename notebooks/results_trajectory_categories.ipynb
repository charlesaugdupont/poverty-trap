{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957e52ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from SALib.sample import sobol\n",
    "from network_model import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import lzma\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({\"font.size\" : 15,\n",
    "                     \"figure.dpi\" : 100, \n",
    "                     \"grid.alpha\" : 0.3, \n",
    "                     \"axes.grid\": True, \n",
    "                     \"axes.axisbelow\" : True,\n",
    "                     \"figure.figsize\":(8,6),\n",
    "                     \"mathtext.fontset\":\"cm\",\n",
    "                     \"xtick.labelsize\": 14,\n",
    "                     \"ytick.labelsize\": 14,\n",
    "                     \"axes.labelsize\": 16, \n",
    "                     \"legend.fontsize\": 13.5})\n",
    "USE_TEX = False\n",
    "if USE_TEX:\n",
    "    plt.rc(\"text\", usetex=True)\n",
    "    plt.rc(\"text.latex\", preamble=r\"\"\"\n",
    "     \\usepackage{times}\n",
    "     \\usepackage{mathptmx}\"\"\")\n",
    "else:\n",
    "    plt.rc(\"text\", usetex=False)\n",
    "plt.rc(\"font\", family=\"serif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f0e21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(W):\n",
    "    n = len(W)\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += sum(np.abs(W[i]-W))\n",
    "    return total / (2 * n**2 * np.mean(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0018813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_1(data):\n",
    "    decreasing = []\n",
    "    for i in range(len(data)):\n",
    "        d = data[i]\n",
    "        mono_dec = True\n",
    "        for row in d:\n",
    "            if max(row[1:] - row[:-1]) > 0:\n",
    "                mono_dec = False\n",
    "                break\n",
    "        if mono_dec:\n",
    "            decreasing.append(i)\n",
    "    return decreasing\n",
    "\n",
    "\n",
    "def category_2(data, ignore):\n",
    "    increase_less_initial = []\n",
    "    for i in range(len(data)):\n",
    "        if i not in ignore:\n",
    "            d = data[i]\n",
    "            if np.all(np.max(data[i], axis=1) == data[i][:,0]):\n",
    "                increase_less_initial.append(i)\n",
    "    return increase_less_initial\n",
    "\n",
    "\n",
    "def category_3(data, ignore):\n",
    "    surpass_end_poor = []\n",
    "    for i in range(len(data)):\n",
    "        if i not in ignore:\n",
    "            if max(data[i].T[-1]) < 0.1:\n",
    "                surpass_end_poor.append(i)\n",
    "    return surpass_end_poor\n",
    "\n",
    "\n",
    "def category_4(data, ignore):\n",
    "    two_equilibria_less_initial = []\n",
    "    for i in range(len(data)):\n",
    "        if i not in ignore:\n",
    "            if np.all(data[i].T[-1] < data[i].T[0]):\n",
    "                two_equilibria_less_initial.append(i)\n",
    "    return two_equilibria_less_initial\n",
    "\n",
    "\n",
    "def category_5(data, ignore):\n",
    "    two_equilibria_richer = []\n",
    "    for i in range(len(data)):\n",
    "        if i not in ignore:\n",
    "            two_equilibria_richer.append(i)\n",
    "    return two_equilibria_richer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a4a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [\"../data/sobol/concat_W_arrays\", \n",
    "               \"../data/sobol/concat_W_arrays_random\", \n",
    "               \"../data/sobol/concat_W_arrays_cpt\",\n",
    "               \"../data/sobol/concat_W_arrays_cpt_random/\"]\n",
    "\n",
    "labels = [\"MPT (Holme-Kim)\", \n",
    "          \"MPT (Random)\", \n",
    "          \"CPT (Holme-Kim)\",\n",
    "          \"CPT (Random)\"]\n",
    "\n",
    "communities_file = [\"../augmented_communities.pickle\", \n",
    "                    \"../augmented_communities_random.pickle\",\n",
    "                    \"../augmented_communities.pickle\",\n",
    "                    \"../augmented_communities_random.pickle\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1a295",
   "metadata": {},
   "source": [
    "# Analysis at agent level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc5da7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running analysis for CPT (Random)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:31:19<00:00, 547.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RESULTS ---\n",
      "{0: [1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024], 1: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 2: [6968, 6341, 5670, 6300, 6278, 6033, 6956, 6687, 6621, 6510], 3: [91, 272, 276, 87, 74, 136, 159, 142, 117, 95], 4: [543, 558, 568, 595, 500, 474, 495, 571, 507, 558], 5: [305, 729, 843, 535, 439, 760, 352, 343, 387, 676], 6: [285, 292, 835, 675, 901, 789, 230, 449, 560, 353]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gini_cutoffs = None\n",
    "RESULTS = {}\n",
    "\n",
    "for dir_idx, D in enumerate(directories):\n",
    "\n",
    "    print(f\"Running analysis for {labels[dir_idx]}...\")\n",
    "\n",
    "    category_counts = {i:[] for i in range(7)}\n",
    "    gini_coefficients = []\n",
    "\n",
    "    for f in tqdm(os.listdir(D)):\n",
    "\n",
    "        data = pickle.load(lzma.open(os.path.join(D,f)))\n",
    "\n",
    "        cat1 = category_1(data)\n",
    "        cat2 = category_2(data, cat1)\n",
    "        cat3 = category_3(data, cat1+cat2)\n",
    "        cat4 = category_4(data, cat1+cat2+cat3)\n",
    "        cat5 = category_5(data, cat1+cat2+cat3+cat4)\n",
    " \n",
    "        assert len(cat1+cat2+cat3+cat4+cat5) == len(data)\n",
    "\n",
    "        gini_coefficients.append([gini(data[i].T[-1]) for i in cat5])\n",
    "\n",
    "        for i,cat in enumerate([cat1, cat2, cat3, cat4]):\n",
    "            category_counts[i].append(len(cat))\n",
    "\n",
    "    if gini_cutoffs is None:\n",
    "        concatenated_gini_coefficients = np.concatenate(gini_coefficients)\n",
    "        sorted_coeffs = np.array(sorted(concatenated_gini_coefficients))\n",
    "        split_arrays = np.array_split(sorted_coeffs, 3)\n",
    "        gini_cutoffs = [arr[-1] for arr in split_arrays]\n",
    "\n",
    "    for rep in gini_coefficients:\n",
    "        gini_categories = {cutoff:[] for cutoff in gini_cutoffs}\n",
    "        for coeff in rep:\n",
    "            for key in gini_categories:\n",
    "                if coeff <= key:\n",
    "                    gini_categories[key].append(coeff)\n",
    "                    break\n",
    "\n",
    "        for i,cutoff in enumerate(gini_categories):\n",
    "            category_counts[4+i].append(len(gini_categories[cutoff]))\n",
    "\n",
    "    RESULTS[labels[dir_idx]] = category_counts\n",
    "    print(\"--- RESULTS ---\")\n",
    "    print(category_counts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"category_count_results_individual.pickle\", \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4940d85c",
   "metadata": {},
   "source": [
    "# Analysis at community level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cbaab76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running analysis for CPT (Random)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [21:41<00:00, 130.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RESULTS ---\n",
      "{0: [1395, 1276, 1290, 1361, 1425, 1357, 1372, 1526, 1353, 1613], 1: [599, 421, 203, 340, 407, 399, 533, 286, 658, 825], 2: [6051, 5890, 5336, 5702, 5544, 5382, 6183, 5959, 5703, 5152], 3: [278, 642, 558, 454, 648, 475, 531, 394, 384, 363], 4: [401, 417, 393, 475, 417, 341, 352, 432, 346, 390], 5: [285, 370, 594, 389, 274, 563, 185, 322, 397, 585], 6: [207, 200, 842, 495, 501, 699, 60, 297, 375, 288]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gini_cutoffs = None\n",
    "RESULTS = {}\n",
    "\n",
    "for dir_idx, D in enumerate(directories):\n",
    "    \n",
    "    with open(communities_file[dir_idx], \"rb\") as f:\n",
    "        communities = pickle.load(f) \n",
    "    community_keys = sorted(list(communities.keys()))[:-1]\n",
    "    \n",
    "    print(f\"Running analysis for {labels[dir_idx]}...\")\n",
    "    \n",
    "    category_counts = {i:[] for i in range(7)}\n",
    "    gini_coefficients = []\n",
    "    \n",
    "    for f in tqdm(os.listdir(D)):\n",
    "        data = pickle.load(lzma.open(os.path.join(D,f)))\n",
    "        data_communities = np.zeros((data.shape[0], len(community_keys), data.shape[2]))\n",
    "        for c in community_keys:\n",
    "            for i in range(len(data)):\n",
    "                data_communities[i][c] = np.mean(data[i][communities[c]], axis=0)\n",
    "        \n",
    "        data = data_communities\n",
    "        cat1 = category_1(data)\n",
    "        cat2 = category_2(data, cat1)\n",
    "        cat3 = category_3(data, cat1+cat2)\n",
    "        cat4 = category_4(data, cat1+cat2+cat3)\n",
    "        cat5 = category_5(data, cat1+cat2+cat3+cat4)\n",
    "        \n",
    "        assert len(cat1+cat2+cat3+cat4+cat5) == len(data)\n",
    "\n",
    "        gini_coefficients.append([gini(data[i].T[-1]) for i in cat5])\n",
    "\n",
    "        for i,cat in enumerate([cat1, cat2, cat3, cat4]):\n",
    "            category_counts[i].append(len(cat))\n",
    "\n",
    "    if gini_cutoffs is None:\n",
    "        concatenated_gini_coefficients = np.concatenate(gini_coefficients)\n",
    "        sorted_coeffs = np.array(sorted(concatenated_gini_coefficients))\n",
    "        split_arrays = np.array_split(sorted_coeffs, 3)\n",
    "        gini_cutoffs = [arr[-1] for arr in split_arrays]\n",
    "\n",
    "    for rep in gini_coefficients:\n",
    "        gini_categories = {cutoff:[] for cutoff in gini_cutoffs}\n",
    "        for coeff in rep:\n",
    "            for key in gini_categories:\n",
    "                if coeff <= key:\n",
    "                    gini_categories[key].append(coeff)\n",
    "                    break\n",
    "\n",
    "        for i,cutoff in enumerate(gini_categories):\n",
    "            category_counts[4+i].append(len(gini_categories[cutoff]))\n",
    "\n",
    "    RESULTS[labels[dir_idx]] = category_counts\n",
    "    print(\"--- RESULTS ---\")\n",
    "    print(category_counts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ccde2807",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"category_count_results_communities.pickle\", \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
